---
title: "DMTA2"
author: "S"
date: "14 de mayo de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


**Before start:**

* Clean the Environment
```{r}
rm(list=ls())
```

* Load Packages
```{r}
library("knitr")
library("StatRank")
library("ggplot2")
library("caret")
library("tidyr")
library("dplyr")
library("corrplot")
library("unbalanced")
library("gbm")
library("ranger")

# Citation
toBibtex(citation("knitr"))

write_bib(x = .packages(), file = "", tweak = TRUE, width = NULL, 
    prefix = getOption("knitr.bib.prefix", "R-"))

```


* Functions definition
```{r}
# Function to create multiplots
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


```{r}
# Ranking functions
rank_prediction <- function(df){
    "
    Ranks search IDs according to prediction scores

    The dataframe given as a parameter 
    must contain the following columns
    in order to rank:
        - srch_id (the search IDs)
        - prediction (the prediction per row (higher score -> better rank))

    Other important columns are:
        - prop_id (for sorting the property IDs for the prediction file)
        - relevance (relevance score for calculating the NDCG of the test set)
    "
    
    res <- df[order(df$srch_id,df$prediction,decreasing=c(FALSE,TRUE)),]
    
    rownames(res) <- NULL
    
    return(res)
}
```

```{r}
# NDCG Score
ndcg_score <- function(i,data){
    group <- data[data[,"srch_id"] == i,]
    
    #dcg <- group[,"relevance"] / log2((1:nrow(group))+1)
    #idcg <- group[order(group$relevance,decreasing=TRUE),"relevance"] / log2((1:nrow(group))+1)
    #return(sum(dcg) / sum(idcg))
    
    return(Evaluation.NDCG(nrow(group):1,group[,"relevance"]))
}

ndcg_mean <- function(df){
    "
    Calculates the average ndcg score for a 
    given ensemble of ranked searches.

    The dataframe given as a parameter 
    must contain the following columns
    in order to calculate the ndcg score:
        - srch_id (the search IDs)
        - relevance (relevance score for calculating the NDCG of the test set)
    "
    ndcg <- sapply(unique(df[,"srch_id"]),data=df,FUN=ndcg_score)
    return(mean(ndcg,na.rm = TRUE))
}



```


* Set path and load the data
```{r}
# Stablishing the working directory and the file paths 
setwd("C:/Users/11729589/Desktop/Data")

# Opening the files 
all_train <- read.csv("full_train.csv", header = TRUE)
test <- read.csv(file_test, header = TRUE)

```


## Data Understanding

### Summary

### Visualize the Data

* Visualization of NA's and new hotels 
```{r}
# Change the NAs to character to be taken into account in the plot
all_train$prop_review_score[is.na(all_train$prop_review_score)] <- "NA"

# Plot of the Hotel rating score for all hotels
p1 <- ggplot(all_train, aes(x=prop_review_score)) + geom_bar(fill="steelblue") + ggtitle("A") + xlab("Hotel Review Score")

# Plot of the score of the booked hotels, to see if the users prefer a new hotel (NA) or a hotel with the woorst case scenario (0)
pre_NA_visual <-table(Rating=all_train$prop_review_score, Booked= as.logical(all_train$booking_bool))
pre_NA_visual <- as.data.frame(prop.table(pre_NA_visual, 1)) # row percentages 
NA_visual <- pre_NA_visual[pre_NA_visual$Rating=="NA"| pre_NA_visual$Rating=="0"| pre_NA_visual$Rating=="1",]
NA_visual <- NA_visual[NA_visual$Booked==TRUE,]

p2 <- ggplot(NA_visual, aes(x = Rating, y = Freq)) + 
  geom_bar(stat = "identity", position = position_dodge(), fill="steelblue") + 
  ggtitle("B") + xlab("Hotel Review Score")

multiplot(p1, p2, cols=2)

# Remove useless Data from Environment
rm(NA_visual, p1, p2, pre_NA_visual)

# Re-change the type of variable to numeric
all_train$prop_review_score <- as.numeric(all_train$prop_review_score)
```


* Visualization of the unbalanced data
```{r}

balance_visual <- data.frame(Type = c("click","book", "ignored"), Value=c(sum(all_train$click_bool==1), sum(all_train$booking_bool==1), sum(all_train$ignored_bool==1)))

ggplot(balance_visual, aes(x=Type, y=Value, fill=Type)) + 
  geom_histogram(stat="identity")


# Remove useless Data from Environment
rm(balance_visual)
```


## Data Preparation

### Feature engineering

* Factorize variables
```{r}
factor_cols <- unlist(lapply(all_train, is.factor))
factor_cols["date_time"] <- FALSE

#train[factor_cols] <- as.numeric(as.character(train[factor_cols]))

for (name in colnames(all_train[factor_cols])){
    all_train[name] <- as.numeric(sub('NULL',NA,as.character(all_train[name][,1])))
}
```

* Feature creation
```{r}
all_train$room_count <- all_train$srch_room_count * max(all_train$srch_booking_window) + all_train$srch_booking_window

all_train$persons_count <- all_train$srch_adults_count * max(all_train$srch_children_count) + all_train$srch_children_count

all_train$prop_starrating_monotonic <- abs(all_train$prop_starrating - mean(all_train$prop_starrating[all_train$booking_bool == 1]))


# Create the ignored column
all_train$ignored_bool <- ifelse(all_train$click_bool == 0 & all_train$booking_bool == 0, 1, 0)


# Add relevance targets
all_train$relevance <- numeric(nrow(all_train))

booked <- all_train[,"booking_bool"] == 1
clicked <- !booked & (all_train[,"click_bool"] == 1)

all_train$relevance[booked] <- 5
all_train$relevance[clicked] <- 1
```


### Split the data
```{r}
#Group by search ID to then split the test set
all_train <- all_train %>%
  group_by(srch_id)

#Split of the test set
all_length <- nrow(all_train)
splity <- all_length*0.15
splity <- 743764 # Adjust cutoff depending on the srch_id 
test <- all_train[1:splity,]
train <- all_train[(splity+1):all_length,]

# Remove useless Data from Environment
rm(all_train, splity)
```


### Visualization of the processed data: Correlation Matrix

* Calculate the percentage of NAs in a column
```{r}
# Get NA value booleans
nas <- is.na(train)

len.nas <- length(nas[,1])

# Initialize NA vector
na.vec <- vector(mode="integer",length=length(colnames(train)))

# Sum the NA values and fill NA vector
for (i in 1:length(na.vec)){
    na.vec[i] <- sum(nas[,i]) / len.nas
}

# Create bar plot Data Frame
na.df <- data.frame(colnames(train),na.vec)
colnames(na.df) <- c("attribute","missing_values")

# # Sort by number of missing values
# position <- arrange(na.df,missing_values)["attribute"][,1]

rm(nas,len.nas,na.vec, i)

```

* Preparation of the data for the correlation matrix
```{r}
variables_without_nas <- na.df$attribute[na.df$missing_values<=0.75]
variables_without_nas <- as.character(variables_without_nas)
no.na_train <- train[variables_without_nas]

df.nums <- subset(no.na_train,select=c(-srch_id, -booking_bool,-click_bool,-ignored_bool))

```

* Correlation Matrix
```{r}
# type = "upper"
corrplot(cor(df.nums),method="color",type="upper",tl.cex=0.6)
```


### Missing values

* Elimination of variables
```{r}
train$visitor_hist_starrating <- NULL
train$visitor_hist_adr_usd <- NULL
train$orig_destination_distance <- NULL
train$visitor_location_country_id <- NULL
train$prop_location_score1 <- NULL
train$srch_adults_count <- NULL
train$srch_children_count <- NULL
train$srch_room_count <- NULL
train$prop_starrating <- NULL
train$prop_review_score <- NULL
```


### Balance the data
```{r}

# Balance the Train
train$ignored_bool <- ifelse(train$click_bool == 0 & train$booking_bool == 0, 0, 1) # Change previous 1 to 0, then this will be changed again, it's only in order to be able to run the function ubBalance()

output <- as.factor(train$ignored_bool) 
input <- train

data <- ubBalance(X=input, Y=output, type = "ubUnder", perc = 40) #apply undersampling
underTrain <- data.frame(data$X) #undersampled dataset





#Visualizations to compare data unbalanced and balanced
unbalance_visual <- data.frame(Type = c("Click","Book", "Ignored"), Value=c(sum(train$click_bool==1), sum(train$booking_bool==1), sum(train$ignored_bool==0)))

p1 <- ggplot(unbalance_visual, aes(x=Type, y=Value, fill=Type)) + 
  geom_histogram(stat="identity", show.legend = FALSE) +
  ggtitle("Unbalanced Data")

balance_visual <- data.frame(Type = c("Click","Book", "Ignored"), Value=c(sum(underTrain$click_bool==1), sum(underTrain$booking_bool==1), sum(underTrain$ignored_bool==0)))  # We'll only do one plot since it's already representative of how the other splits(validation and test) are balanced. 

p2 <- ggplot(balance_visual, aes(x=Type, y=Value, fill=Type)) + 
  geom_histogram(stat="identity", show.legend = FALSE) +
  ggtitle("Balanced Data")

multiplot(p1, p2, cols=2)



# Test Balance
test$ignored_bool <- ifelse(test$click_bool == 0 & test$booking_bool == 0, 0, 1) # Change previous 1 to 0, then this will be changed again, it's only in order to be able to run the function ubBalance()
output <- as.factor(test$ignored_bool) 
input <- test

data <- ubBalance(X=input, Y=output, type = "ubUnder", perc = 40) #apply undersampling
underTest <- data.frame(data$X) #undersampled dataset





# Remove useless Data from Envirinment
rm(balance_visual, data, input, unbalance_visual, p1, p2, output, train, test)




# Change values 0 to 1 of the "ignored_bool" variable in the new balanced data sets
underTrain$ignored_bool <- ifelse(underTrain$click_bool == 0 & underTrain$booking_bool == 0, 1, 0) 
underTest$ignored_bool <- ifelse(underTest$click_bool == 0 & underTest$booking_bool == 0, 1, 0) 

```


## Modelling and Evaluation

* Data preparation for modelling
```{r}
underTrain$booked <- ifelse(underTrain$relevance == 5, 1, 0)
underTrain$booked <- as.factor(underTrain$booked)
```


### Logistic regression

* Data Processing
```{r}
lr_train <- subset(underTrain, select=c(-srch_id,-position,-click_bool,-booking_bool, -ignored_bool, -gross_bookings_usd, -relevance))
```

* Modelling
```{r}
glm.fit <- glm(booked ~ ., data = lr_train, family =  "binomial")
```

* Prediction 
```{r}
pred_logist <- predict(glm.fit, newdata = Test)

df <- data.frame(srch_id= Test$srch_id, prop_id= Test$prop_id, prediction=pred_logist, relevance=Test$relevance)

ranking <- rank_prediction(df) 
```

* Evaluation
```{r}
ndcg_mean(ranking)
```


### Ranger

* Data Processing
```{r}
ranger_train <- subset(underTrain, select=c(-srch_id,-position,-click_bool,-booking_bool, -ignored_bool, -gross_bookings_usd, -relevance))
```


With all the variables

* Modelling
```{r}
ranger_model = ranger(booked ~ ., data = ranger_train, importance = "permutation")
imp <- importance(ranger_model)
```

* Prediction
```{r}
pred_ranger <- predict(ranger_model, data = Test)

df <- data.frame(srch_id= Test$srch_id, prop_id = Test$prop_id, prediction=as.numeric(pred_ranger$predictions), relevance = Test$relevance)

ranking <- rank_prediction(df)
```

* Evaluation
```{r}
ndcg_mean(ranking)
```


With the importnat variables

* Data Processing
```{r}
ranger_train2 <- subset(ranger_train, select=c(imp$variable[imp$imp >= exp(-5)], "booked"))
```

* Modelling
```{r}
ranger_model2 = ranger(booked ~ ., data = ranger_train2)
```

* Prediction
```{r}
pred_ranger2 <- predict(ranger_model2, data = Test)

df2 <- data.frame(srch_id= Test$srch_id, prop_id = Test$prop_id, prediction=as.numeric(pred_ranger2$predictions), relevance = Test$relevance)

ranking2 <- rank_prediction(df2)
```

* Evaluation
```{r}
ndcg_mean(ranking2)
```


### Plot Important variables
```{r}
impr <- as.data.frame(imp)
impr <- add_rownames(impr, "variable")
Ranger <- data.frame(Model="Ranger", Variable=imp$variable[imp$imp >= exp(-5)], Importance=imp$imp[imp$imp >= exp(-5)])

impl <- varImp(glm.fit)
impl <- add_rownames(impl, "variable")
Logi <- data.frame(Model="GLM", Variable=impl$variable[impl$Overall >= 20], Importance=impl$Overall[impl$Overall >= 20])

all_data <- rbind(Logi,Ranger)

ggplot(all_data, aes(x=Variable,y=Importance, fill=Model)) + geom_bar(stat = "identity")
```

