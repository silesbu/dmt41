{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining techniques: Assignment 2\n",
    "\n",
    "This environment makes use of Python version 3.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = \"/home/kevin/data_mining/data/assignment2/Split_Data_DM/train.csv\"\n",
    "validPath = \"/home/kevin/data_mining/data/assignment2/Split_Data_DM/validation.csv\"\n",
    "testPath = \"/home/kevin/data_mining/data/assignment2/Split_Data_DM/test.csv\"\n",
    "\n",
    "traincols = list(pd.read_csv(trainPath,nrows=1).columns.values)\n",
    "validcols = list(pd.read_csv(validPath,nrows=1).columns.values)\n",
    "testcols = list(pd.read_csv(testPath,nrows=1).columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant date_time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_values(path):\n",
    "    attributes = [\"date_time\"]\n",
    "    df = pd.read_csv(path,usecols=attributes)\n",
    "\n",
    "    df_dates = pd.to_datetime(df[\"date_time\"])\n",
    "\n",
    "    time_df = pd.DataFrame({\"date_year\":df_dates.dt.year,\n",
    "                            \"date_month\":df_dates.dt.month,\n",
    "                            \"date_hour\":df_dates.dt.hour})\n",
    "\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize missing values dictionary\n",
    "imp = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin-destination distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs before: 1126222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2344622/2344622 [03:17<00:00, 11856.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs after pairs: 331833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/kevin/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs after visitor ID imputation: 15296\n",
      "Number of NaNs after: 0\n"
     ]
    }
   ],
   "source": [
    "attributes = [\"visitor_location_country_id\",\"prop_country_id\",\"orig_destination_distance\"]\n",
    "df = pd.read_csv(trainPath,usecols=attributes)\n",
    "\n",
    "max_n = max(np.max(df[\"visitor_location_country_id\"]),np.max(df[\"prop_country_id\"]))\n",
    "\n",
    "mean_distances = np.empty((max_n,max_n))\n",
    "mean_distances[:,:] = np.nan\n",
    "\n",
    "dist_sum = np.zeros((max_n,max_n))\n",
    "dist_count = np.zeros((max_n,max_n))\n",
    "\n",
    "dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "\n",
    "print(\"Number of NaNs before:\",np.sum(dist_nans))\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "i = np.maximum(df[\"visitor_location_country_id\"],df[\"prop_country_id\"]) - 1\n",
    "j = np.minimum(df[\"visitor_location_country_id\"],df[\"prop_country_id\"]) - 1\n",
    "\n",
    "# Fill NAs with distance pairs\n",
    "with tqdm.tqdm(total=np.sum(~dist_nans)) as pbar:\n",
    "    for n in np.arange(len(df))[~dist_nans]:\n",
    "        dist_sum[i[n],j[n]] += df.loc[n,\"orig_destination_distance\"]\n",
    "        dist_count[i[n],j[n]] += 1\n",
    "        \n",
    "        pbar.update()\n",
    "\n",
    "mean_indices = (dist_count != 0)\n",
    "mean_distances[mean_indices] = dist_sum[mean_indices] / dist_count[mean_indices]\n",
    "\n",
    "df.loc[dist_nans,\"orig_destination_distance\"] = mean_distances[i[dist_nans],j[dist_nans]]\n",
    "    \n",
    "dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "print(\"Number of NaNs after pairs:\",np.sum(dist_nans))\n",
    "\n",
    "# Fill NAs with medians per visitor location ID\n",
    "visitor_medians = np.zeros(np.max(df[\"visitor_location_country_id\"]))\n",
    "visitor_medians[:] = np.nan\n",
    "\n",
    "vis_loc_ids = df[\"visitor_location_country_id\"] - 1\n",
    "for n in range(len(visitor_medians)):\n",
    "    vals = (vis_loc_ids == n) & ~dist_nans\n",
    "    nans = (vis_loc_ids == n) & dist_nans\n",
    "    \n",
    "    dist_median = np.median(df.loc[vals,\"orig_destination_distance\"])\n",
    "    df.loc[nans,\"orig_destination_distance\"] = dist_median\n",
    "    visitor_medians[n] = dist_median\n",
    "\n",
    "dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "print(\"Number of NaNs after visitor ID imputation:\",np.sum(dist_nans))\n",
    "    \n",
    "# Fill remaining NAs with the median of all distances\n",
    "median_distance = np.median(df.loc[~dist_nans,\"orig_destination_distance\"])\n",
    "df.loc[dist_nans,\"orig_destination_distance\"] = median_distance\n",
    "\n",
    "print(\"Number of NaNs after:\",np.sum(np.isnan(df[\"orig_destination_distance\"])))\n",
    "\n",
    "imp[\"mean_distances\"] = mean_distances\n",
    "imp[\"visitor_medians\"] = visitor_medians\n",
    "imp[\"median_distance\"] = median_distance\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel description columns imputation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"prop_location_score2\",\"srch_query_affinity_score\"]\n",
    "df = pd.read_csv(trainPath,usecols=attributes)\n",
    "\n",
    "imp[\"prop_review_score\"] = 1\n",
    "imp[\"comp\"] = 0\n",
    "\n",
    "nans = np.isnan(df[\"prop_location_score2\"])\n",
    "imp[\"prop_location_score2\"] = np.percentile(df.loc[~nans,\"prop_location_score2\"],25)\n",
    "\n",
    "nans = np.isnan(df[\"srch_query_affinity_score\"])\n",
    "imp[\"srch_query_affinity_score\"] = np.percentile(df.loc[~nans,\"srch_query_affinity_score\"],25)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export train data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_full_dataset(path,cols,omitted,imp):\n",
    "    attributes = [elem for elem in cols if elem not in omitted]\n",
    "    df = pd.read_csv(path,usecols=attributes)\n",
    "\n",
    "    # Impute origin-distance values\n",
    "\n",
    "    dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "    i = np.maximum(df[\"visitor_location_country_id\"],df[\"prop_country_id\"]) - 1\n",
    "    j = np.minimum(df[\"visitor_location_country_id\"],df[\"prop_country_id\"]) - 1\n",
    "    df.loc[dist_nans,\"orig_destination_distance\"] = imp[\"mean_distances\"][i[dist_nans],j[dist_nans]]\n",
    "    \n",
    "    dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "    vis_loc_ids = df[\"visitor_location_country_id\"] - 1\n",
    "    for n in range(len(visitor_medians)):\n",
    "        nans = (vis_loc_ids == n) & dist_nans\n",
    "        df.loc[nans,\"orig_destination_distance\"] = imp[\"visitor_medians\"][n]\n",
    "    \n",
    "    dist_nans = np.isnan(df[\"orig_destination_distance\"])\n",
    "    df.loc[dist_nans,\"orig_destination_distance\"] = imp[\"median_distance\"]\n",
    "    \n",
    "    # Impute the rest of the missing values\n",
    "    \n",
    "    nans = np.isnan(df[\"prop_review_score\"])\n",
    "    df.loc[nans,\"prop_review_score\"] = imp[\"prop_review_score\"]\n",
    "\n",
    "    nans = np.isnan(df[\"prop_location_score2\"])\n",
    "    df.loc[nans,\"prop_location_score2\"] = imp[\"prop_location_score2\"]\n",
    "\n",
    "    nans = np.isnan(df[\"srch_query_affinity_score\"])\n",
    "    df.loc[nans,\"srch_query_affinity_score\"] = imp[\"srch_query_affinity_score\"]\n",
    "\n",
    "    for n in range(1,9):\n",
    "        nans = np.isnan(df[\"comp%i_rate\" % (n)])\n",
    "        df.loc[nans,\"comp%i_rate\" % (n)] = imp[\"comp\"]\n",
    "\n",
    "        nans = np.isnan(df[\"comp%i_inv\" % (n)])\n",
    "        df.loc[nans,\"comp%i_inv\" % (n)] = imp[\"comp\"]\n",
    "\n",
    "        nans = np.isnan(df[\"comp%i_rate_percent_diff\" % (n)])\n",
    "        df.loc[nans,\"comp%i_rate_percent_diff\" % (n)] = imp[\"comp\"]\n",
    "\n",
    "    # Extract and append relevant date attributes\n",
    "    time_df = extract_date_values(path)\n",
    "\n",
    "    for column in time_df.columns.values:\n",
    "        df[column] = time_df[column]\n",
    "\n",
    "    del time_df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct dataframe to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load dataframe\\n\\nomitted = [\"date_time\",\"visitor_hist_starrating\",\"visitor_hist_adr_usd\",\"gross_bookings_usd\"]\\nattributes = [elem for elem in traincols if elem not in omitted]\\n\\ntrain = pd.read_csv(trainPath,usecols=attributes)\\n\\n# Impute missing values\\n\\ntrain[\"orig_destination_distance\"] = train_distances\\n\\nnans = np.isnan(train[\"prop_review_score\"])\\ntrain.loc[nans,\"prop_review_score\"] = review_imp\\n\\nnans = np.isnan(train[\"prop_location_score2\"])\\ntrain.loc[nans,\"prop_location_score2\"] = location_score2_imp\\n\\nnans = np.isnan(train[\"srch_query_affinity_score\"])\\ntrain.loc[nans,\"srch_query_affinity_score\"] = srch_query_affinity_imp\\n\\nfor n in range(1,9):\\n    nans = np.isnan(train[\"comp%i_rate\" % (n)])\\n    train.loc[nans,\"comp%i_rate\" % (n)] = comp_imp\\n    \\n    nans = np.isnan(train[\"comp%i_inv\" % (n)])\\n    train.loc[nans,\"comp%i_inv\" % (n)] = comp_imp\\n    \\n    nans = np.isnan(train[\"comp%i_rate_percent_diff\" % (n)])\\n    train.loc[nans,\"comp%i_rate_percent_diff\" % (n)] = comp_imp\\n\\n# Extract and append relevant date attributes\\n\\ntrain_time_df = extract_date_values(path)\\n\\nfor column in train_time_df.columns.values:\\n    train[column] = train_time_df[column]\\n    \\ndel train_time_df\\n\\ntrain.head()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load dataframe\n",
    "\n",
    "omitted = [\"date_time\",\"visitor_hist_starrating\",\"visitor_hist_adr_usd\",\"gross_bookings_usd\"]\n",
    "attributes = [elem for elem in traincols if elem not in omitted]\n",
    "\n",
    "train = pd.read_csv(trainPath,usecols=attributes)\n",
    "\n",
    "# Impute missing values\n",
    "\n",
    "train[\"orig_destination_distance\"] = train_distances\n",
    "\n",
    "nans = np.isnan(train[\"prop_review_score\"])\n",
    "train.loc[nans,\"prop_review_score\"] = review_imp\n",
    "\n",
    "nans = np.isnan(train[\"prop_location_score2\"])\n",
    "train.loc[nans,\"prop_location_score2\"] = location_score2_imp\n",
    "\n",
    "nans = np.isnan(train[\"srch_query_affinity_score\"])\n",
    "train.loc[nans,\"srch_query_affinity_score\"] = srch_query_affinity_imp\n",
    "\n",
    "for n in range(1,9):\n",
    "    nans = np.isnan(train[\"comp%i_rate\" % (n)])\n",
    "    train.loc[nans,\"comp%i_rate\" % (n)] = comp_imp\n",
    "    \n",
    "    nans = np.isnan(train[\"comp%i_inv\" % (n)])\n",
    "    train.loc[nans,\"comp%i_inv\" % (n)] = comp_imp\n",
    "    \n",
    "    nans = np.isnan(train[\"comp%i_rate_percent_diff\" % (n)])\n",
    "    train.loc[nans,\"comp%i_rate_percent_diff\" % (n)] = comp_imp\n",
    "\n",
    "# Extract and append relevant date attributes\n",
    "\n",
    "train_time_df = extract_date_values(path)\n",
    "\n",
    "for column in train_time_df.columns.values:\n",
    "    train[column] = train_time_df[column]\n",
    "    \n",
    "del train_time_df\n",
    "\n",
    "train.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv(\"/home/kevin/data_mining/data/assignment2/full_train.csv\",sep=',',index=False)\n",
    "\n",
    "#del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>...</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>ignored_bool</th>\n",
       "      <th>relevance</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>107500</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>109533</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>114103</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>116661</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>119030</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  prop_country_id  prop_id  \\\n",
       "0    49765        5                          219              219   107500   \n",
       "1    49765        5                          219              219   109533   \n",
       "2    49765        5                          219              219   114103   \n",
       "3    49765        5                          219              219   116661   \n",
       "4    49765        5                          219              219   119030   \n",
       "\n",
       "   prop_starrating  prop_review_score  prop_brand_bool  prop_location_score1  \\\n",
       "0                4                4.5                0                  2.56   \n",
       "1                3                4.0                0                  3.43   \n",
       "2                4                3.5                1                  3.95   \n",
       "3                3                3.0                0                  3.53   \n",
       "4                2                2.5                0                  4.03   \n",
       "\n",
       "   prop_location_score2    ...      comp8_rate  comp8_inv  \\\n",
       "0                0.0222    ...             0.0        0.0   \n",
       "1                0.1024    ...             0.0        0.0   \n",
       "2                0.0646    ...             0.0        0.0   \n",
       "3                0.0998    ...             0.0        0.0   \n",
       "4                0.1256    ...             0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  booking_bool  ignored_bool  relevance  \\\n",
       "0                      0.0           0             0             1          0   \n",
       "1                      0.0           0             0             1          0   \n",
       "2                      0.0           0             0             1          0   \n",
       "3                      0.0           0             0             1          0   \n",
       "4                      0.0           0             0             1          0   \n",
       "\n",
       "   date_hour  date_month  date_year  \n",
       "0         14           6       2013  \n",
       "1         14           6       2013  \n",
       "2         14           6       2013  \n",
       "3         14           6       2013  \n",
       "4         14           6       2013  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omitted = [\"date_time\",\"visitor_hist_starrating\",\"visitor_hist_adr_usd\",\"gross_bookings_usd\"]\n",
    "train = construct_full_dataset(trainPath,traincols,omitted,imp)\n",
    "\n",
    "print(\"NaNs: %i\" % np.sum(train.isnull().values))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"/home/kevin/data_mining/data/assignment2/Split_Data_DM/mod_train.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>...</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>ignored_bool</th>\n",
       "      <th>relevance</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>107528</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>113016</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>120827</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49765</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>135415</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49766</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>21167</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  prop_country_id  prop_id  \\\n",
       "0    49765        5                          219              219   107528   \n",
       "1    49765        5                          219              219   113016   \n",
       "2    49765        5                          219              219   120827   \n",
       "3    49765        5                          219              219   135415   \n",
       "4    49766        5                          219              219    21167   \n",
       "\n",
       "   prop_starrating  prop_review_score  prop_brand_bool  prop_location_score1  \\\n",
       "0                3                3.5                0                  2.77   \n",
       "1                3                3.5                0                  3.22   \n",
       "2                3                3.5                0                  4.03   \n",
       "3                3                4.0                0                  3.97   \n",
       "4                2                3.5                0                  2.89   \n",
       "\n",
       "   prop_location_score2    ...      comp8_rate  comp8_inv  \\\n",
       "0                0.0061    ...             0.0        0.0   \n",
       "1                0.0103    ...             0.0        0.0   \n",
       "2                0.0969    ...             0.0        0.0   \n",
       "3                0.0833    ...             0.0        0.0   \n",
       "4                0.5140    ...             0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  booking_bool  ignored_bool  relevance  \\\n",
       "0                      0.0           0             0             1          0   \n",
       "1                      0.0           0             0             1          0   \n",
       "2                      0.0           0             0             1          0   \n",
       "3                      0.0           1             1             0          5   \n",
       "4                      0.0           0             0             1          0   \n",
       "\n",
       "   date_hour  date_month  date_year  \n",
       "0         14           6       2013  \n",
       "1         14           6       2013  \n",
       "2         14           6       2013  \n",
       "3         14           6       2013  \n",
       "4         14           6       2013  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omitted = [\"date_time\",\"visitor_hist_starrating\",\"visitor_hist_adr_usd\",\"gross_bookings_usd\"]\n",
    "valid = construct_full_dataset(validPath,validcols,omitted,imp)\n",
    "\n",
    "print(\"NaNs: %i\" % np.sum(valid.isnull().values))\n",
    "\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv(\"/home/kevin/data_mining/data/assignment2/Split_Data_DM/mod_valid.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>...</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>ignored_bool</th>\n",
       "      <th>relevance</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  prop_country_id  prop_id  \\\n",
       "0        1       12                          187              219      893   \n",
       "1        1       12                          187              219    10404   \n",
       "2        1       12                          187              219    21315   \n",
       "3        1       12                          187              219    27348   \n",
       "4        1       12                          187              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  prop_brand_bool  prop_location_score1  \\\n",
       "0                3                3.5                1                  2.83   \n",
       "1                4                4.0                1                  2.20   \n",
       "2                3                4.5                1                  2.20   \n",
       "3                2                4.0                1                  2.83   \n",
       "4                4                3.5                1                  2.64   \n",
       "\n",
       "   prop_location_score2    ...      comp8_rate  comp8_inv  \\\n",
       "0                0.0438    ...             0.0        0.0   \n",
       "1                0.0149    ...             0.0        0.0   \n",
       "2                0.0245    ...             0.0        0.0   \n",
       "3                0.0125    ...            -1.0        0.0   \n",
       "4                0.1241    ...             0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  booking_bool  ignored_bool  relevance  \\\n",
       "0                      0.0           0             0             1          0   \n",
       "1                      0.0           0             0             1          0   \n",
       "2                      0.0           0             0             1          0   \n",
       "3                      5.0           0             0             1          0   \n",
       "4                      0.0           0             0             1          0   \n",
       "\n",
       "   date_hour  date_month  date_year  \n",
       "0          8           4       2013  \n",
       "1          8           4       2013  \n",
       "2          8           4       2013  \n",
       "3          8           4       2013  \n",
       "4          8           4       2013  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omitted = [\"date_time\",\"visitor_hist_starrating\",\"visitor_hist_adr_usd\",\"gross_bookings_usd\"]\n",
    "test = construct_full_dataset(testPath,testcols,omitted,imp)\n",
    "\n",
    "print(\"NaNs: %i\" % np.sum(test.isnull().values))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"/home/kevin/data_mining/data/assignment2/Split_Data_DM/mod_test.csv\",sep=',',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
